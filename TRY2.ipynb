{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Importing Torch and checking if CUDA is available and returning the GPU model\n",
    "\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.94  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Setup complete  (20 CPUs, 15.7 GB RAM, 284.6/953.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Importing Ultralytics and verifying the version\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: roboflow in c:\\users\\vikh8\\appdata\\roaming\\python\\python311\\site-packages (1.1.56)\n",
      "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from roboflow) (2025.1.31)\n",
      "Requirement already satisfied: idna==3.7 in c:\\users\\vikh8\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in c:\\program files\\python311\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\program files\\python311\\lib\\site-packages (from roboflow) (1.4.8)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\python311\\lib\\site-packages (from roboflow) (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\program files\\python311\\lib\\site-packages (from roboflow) (2.1.1)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in c:\\users\\vikh8\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\program files\\python311\\lib\\site-packages (from roboflow) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\vikh8\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in c:\\program files\\python311\\lib\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\program files\\python311\\lib\\site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\vikh8\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\program files\\python311\\lib\\site-packages (from roboflow) (2.3.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\program files\\python311\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\program files\\python311\\lib\\site-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\vikh8\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in c:\\program files\\python311\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vikh8\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\program files\\python311\\lib\\site-packages (from matplotlib->roboflow) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\program files\\python311\\lib\\site-packages (from matplotlib->roboflow) (4.56.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vikh8\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\program files\\python311\\lib\\site-packages (from matplotlib->roboflow) (3.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests->roboflow) (3.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "%pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"tWR5EG59g5CFtyUc1hIl\")\n",
    "project = rf.workspace(\"goddy-mdzze\").project(\"mp2-data-knife-gun\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov11\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 26 12:36:47 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.83                 Driver Version: 572.83         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   75C    P8              9W /   60W |      27MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2808    C+G   ...s\\Win64\\EpicGamesLauncher.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Reporting GPU Stats\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.96 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.94 üöÄ Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11m.pt, data=C:\\\\MP\\\\MP2-DATA-KNIFE-GUN\\\\data.yaml, epochs=2, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 574, in get_dataset\n",
      "    data = check_det_dataset(self.args.data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 312, in check_det_dataset\n",
      "    file = check_file(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 546, in check_file\n",
      "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
      "FileNotFoundError: 'C:\\\\MP\\\\MP2-DATA-KNIFE-GUN\\\\data.yaml' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Program Files\\Python311\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 987, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 785, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 137, in __init__\n",
      "    self.trainset, self.testset = self.get_dataset()\n",
      "                                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 578, in get_dataset\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error ‚ùå {e}\")) from e\n",
      "RuntimeError: Dataset 'C://MP/MP2-DATA-KNIFE-GUN/data.yaml' error  'C:\\\\MP\\\\MP2-DATA-KNIFE-GUN\\\\data.yaml' does not exist\n"
     ]
    }
   ],
   "source": [
    "# Training Process \n",
    "\n",
    "!yolo train model= yolo11m.pt data= \"C:\\\\MP\\\\MP2-DATA-KNIFE-GUN\\\\data.yaml\"dat epochs=2 imgsz=640\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained YOLOv11 model\n",
    "model = YOLO('C:/MP/MP2-DATA-KNIFE-GUN-1/a.yaml')  # Replace with your model path\n",
    "\n",
    "# Path to your test folder containing images\n",
    "test_folder = '\"C:\\\\MP\\\\TEST\"'  # Replace with the actual path to your test folder\n",
    "\n",
    "# Output folder to save the processed images\n",
    "output_folder = 'C:/Users/devna/VSCode Projects/Major Project/FinalCode/Processed_Images'  # Replace with your desired output path\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through the images in the folder\n",
    "for filename in os.listdir(test_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust if needed\n",
    "        img_path = os.path.join(test_folder, filename)\n",
    "\n",
    "        # Load the image\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Perform inference\n",
    "        results = model(img)\n",
    "\n",
    "        # Save the annotated image to the output folder\n",
    "        save_path = os.path.join(output_folder, filename)\n",
    "        results[0].save(save_path)  # Save the image to the specified output folder\n",
    "\n",
    "        # Print detection details (confidence, class, coordinates) for each image\n",
    "        print(f\"Results for {filename}:\")\n",
    "        for i, box in enumerate(results[0].boxes):  # Iterate through all detected boxes\n",
    "            # Access confidence, class, and coordinates\n",
    "            conf = box.conf.item()  # Confidence score for this detection\n",
    "            cls = box.cls.item()  # Class index (0 for fire, etc.)\n",
    "            coordinates = box.xyxy.tolist()  # Bounding box coordinates [x1, y1, x2, y2]\n",
    "            print(f\"Detection {i+1}: Class: {cls}, Confidence: {conf:.2f}, Coordinates: {coordinates}\")\n",
    "\n",
    "print(\"Processing complete. Annotated images are saved in:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained YOLOv11 model\n",
    "model = YOLO('C:/Users/devna/VSCode Projects/Major Project/FinalCode/runs/detect/train/weights/Detection.pt')  # Replace with your model path\n",
    "\n",
    "# Path to your test folder containing images\n",
    "test_folder = 'C:/Users/devna/VSCode Projects/Major Project/FinalCode/Test'  # Replace with the actual path to your test folder\n",
    "\n",
    "# Output folder to save the processed images\n",
    "output_folder = 'C:/Users/devna/VSCode Projects/Major Project/FinalCode/Processed_Images_2'  # Replace with your desired output path\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through the images in the folder\n",
    "for filename in os.listdir(test_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust if needed\n",
    "        img_path = os.path.join(test_folder, filename)\n",
    "\n",
    "        # Load the image\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Perform inference\n",
    "        results = model(img)\n",
    "\n",
    "        # Save the annotated image to the output folder\n",
    "        save_path = os.path.join(output_folder, filename)\n",
    "        results[0].save(save_path)  # Save the image to the specified output folder\n",
    "\n",
    "        # Print detection details (confidence, class, coordinates) for each image\n",
    "        print(f\"Results for {filename}:\")\n",
    "        for i, box in enumerate(results[0].boxes):  # Iterate through all detected boxes\n",
    "            # Access confidence, class, and coordinates\n",
    "            conf = box.conf.item()  # Confidence score for this detection\n",
    "            cls = box.cls.item()  # Class index (0 for fire, etc.)\n",
    "            coordinates = box.xyxy.tolist()  # Bounding box coordinates [x1, y1, x2, y2]\n",
    "            print(f\"Detection {i+1}: Class: {cls}, Confidence: {conf:.2f}, Coordinates: {coordinates}\")\n",
    "\n",
    "print(\"Processing complete. Annotated images are saved in:\", output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
